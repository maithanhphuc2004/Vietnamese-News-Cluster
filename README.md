# ğŸ“° Vietnamese-News-Cluster

## ğŸ”– Model Badges  
*(CÃ¡c mÃ´ hÃ¬nh sá»­ dá»¥ng trong nghiÃªn cá»©u)*

![TFIDF](https://img.shields.io/badge/Embedding-TF--IDF-blue?style=flat-square)
![PhoBERT-base](https://img.shields.io/badge/Embedding-PhoBERT--base-green?style=flat-square)
![PhoBERT-large](https://img.shields.io/badge/Embedding-PhoBERT--large-purple?style=flat-square)
![UMAP](https://img.shields.io/badge/Dimensionality%20Reduction-UMAP-orange?style=flat-square)

![KMeans](https://img.shields.io/badge/Clustering-KMeans-red?style=flat-square)
![Hierarchical](https://img.shields.io/badge/Clustering-Hierarchical--Ward-brown?style=flat-square)
![DBSCAN](https://img.shields.io/badge/Clustering-DBSCAN-yellow?style=flat-square)
![HDBSCAN](https://img.shields.io/badge/Clustering-HDBSCAN-lightgrey?style=flat-square)
![Spectral](https://img.shields.io/badge/Clustering-Spectral-blueviolet?style=flat-square)

![Python](https://img.shields.io/badge/Python-3.10+-blue?style=flat-square&logo=python)
![Status](https://img.shields.io/badge/Status-Active-brightgreen?style=flat-square)
![Dataset](https://img.shields.io/badge/Dataset-7.278%20articles-orange?style=flat-square)

---

# ğŸ“Œ Overview  
*(Tá»•ng quan)*  

This project focuses on clustering electronic news articles using modern NLP techniques and multiple clustering algorithms.  
*(Dá»± Ã¡n táº­p trung phÃ¢n cá»¥m ná»™i dung bÃ i bÃ¡o Ä‘iá»‡n tá»­ báº±ng cÃ¡c ká»¹ thuáº­t NLP hiá»‡n Ä‘áº¡i vÃ  nhiá»u thuáº­t toÃ¡n phÃ¢n cá»¥m khÃ¡c nhau.)*

The workflow includes:  
- Text preprocessing  
- Embedding with TF-IDF and PhoBERT variants  
- Dimensionality reduction via UMAP  
- Clustering using 5 algorithms  
- Evaluation with Silhouette, Daviesâ€“Bouldin, and Calinskiâ€“Harabasz metrics  

---

# ğŸ“‚ Dataset  
*(Táº­p dá»¯ liá»‡u)*  

- Collected from **electronic news articles**  
- Total samples: **7,000+ documents**  
- Preprocessing steps include tokenization, normalization, stopword removal, embedding generation  

---

# ğŸ§  Embedding Methods  
*(CÃ¡c phÆ°Æ¡ng phÃ¡p biá»ƒu diá»…n vÄƒn báº£n)*  

### **1. TF-IDF**  
*(Chuáº©n hÃ³a táº§n suáº¥tâ€“nghá»‹ch Ä‘áº£o táº§n suáº¥t)*  
- Sparse representation  
- Effective for lexical similarity  
- Used as baseline

### **2. PhoBERT-base**  
*(MÃ´ hÃ¬nh ngÃ´n ngá»¯ tiáº¿ng Viá»‡t â€“ phiÃªn báº£n base)*  
- Transformer-based  
- Pretrained on large Vietnamese corpus  
- Captures contextual meaning

### **3. PhoBERT-large**  
*(PhiÃªn báº£n large â€“ máº¡nh hÆ¡n vÃ  chÃ­nh xÃ¡c hÆ¡n)*  
- Better semantic representation  
- Improved clustering separability

### **4. UMAP (Uniform Manifold Approximation and Projection)**  
*(Giáº£m chiá»u dá»¯ liá»‡u)*  
- Reduces embedding from 768D â†’ 2/3D  
- Preserves neighborhood structure  
- Makes clustering easier and more accurate

---

# ğŸ” Clustering Algorithms  
*(CÃ¡c thuáº­t toÃ¡n phÃ¢n cá»¥m)*

## **1. K-Means**  
*(PhÃ¢n cá»¥m K-Means)*  
- Simple and widely used  
- Works best for spherical clusters  
- K chosen using Elbow + Silhouette  
- Applied to TF-IDF and PhoBERT embeddings

## **2. Hierarchical Clustering (Ward linkage)**  
*(PhÃ¢n cá»¥m phÃ¢n cáº¥p â€“ Ward)*  
- Builds dendrogram to visualize cluster hierarchy  
- Does not require choosing K initially  
- Ward linkage minimizes variance  
- Used after UMAP reduction

## **3. DBSCAN**  
*(PhÃ¢n cá»¥m dá»±a trÃªn máº­t Ä‘á»™)*  
- Automatically detects noise points  
- No need to specify K  
- Good for arbitrary-shaped clusters  
- Applied on UMAP-embedded space

## **4. HDBSCAN**  
*(PhiÃªn báº£n nÃ¢ng cáº¥p cá»§a DBSCAN)*  
- Density hierarchy  
- Automatically determines cluster count  
- More stable than DBSCAN  
- Handles variable-density regions

## **5. Spectral Clustering**  
*(PhÃ¢n cá»¥m phá»•)*  
- Uses graph Laplacian  
- Extracts eigenvectors â†’ then runs K-Means  
- Good for complex, non-linear cluster structures  

---

# ğŸ“Š Algorithm Comparison  
*(Báº£ng so sÃ¡nh thuáº­t toÃ¡n)*

### **ğŸ“Œ Comparison based on Silhouette, Daviesâ€“Bouldin, Calinskiâ€“Harabasz across embeddings**
*(So sÃ¡nh dá»±a trÃªn ba chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ trÃªn cÃ¡c embedding khÃ¡c nhau)*

| Algorithm | Embedding | K | Silhouette â†‘ | Daviesâ€“Bouldin â†“ | Calinskiâ€“Harabasz â†‘ |
|----------|-----------|---|--------------|-------------------|----------------------|
| Spectral | TF-IDF (UMAP) | 15 | **0.3120** | 0.8360 | 2259.86 |
| Spectral | PhoBERT-base (UMAP) | 19 | 0.2581 | 0.9197 | 1861.72 |
| Spectral | PhoBERT-large (UMAP) | 8 | **0.3466** | **0.7688** | **2416.71** |
| HDBSCAN | TF-IDF / PhoBERT | â€” | Auto | Auto | â€” |
| DBSCAN | TF-IDF / PhoBERT | â€” | Medium | Medium | â€” |
| K-Means | All embeddings | Varied | Moderate | Medium | Medium |
| Hierarchical (Ward) | All embeddings | Varied | Moderate | Medium | Medium |

(*â†‘ Higher is better, â†“ Lower is better*)  
*(â†‘ Cao hÆ¡n lÃ  tá»‘t hÆ¡n, â†“ Tháº¥p hÆ¡n lÃ  tá»‘t hÆ¡n)*

---

# ğŸ“ˆ Key Findings  
*(Káº¿t luáº­n chÃ­nh)*  

- **PhoBERT-large + Spectral Clustering performs best**, with the highest Silhouette and CH score.  
*(PhoBERT-large + Spectral cho káº¿t quáº£ tá»‘t nháº¥t.)*

- **DBSCAN and HDBSCAN effectively detect natural clusters**, especially with noise handling.  
*(DBSCAN vÃ  HDBSCAN phÃ¡t hiá»‡n cá»¥m tá»± nhiÃªn tá»‘t vÃ  xá»­ lÃ½ nhiá»…u.)*

- **TF-IDF works surprisingly well**, especially after UMAP reduction.  
*(TF-IDF váº«n hoáº¡t Ä‘á»™ng tá»‘t sau khi giáº£m chiá»u báº±ng UMAP.)*

- **Hierarchical Clustering + Ward linkage** provides clean dendrogram visualization.  
*(PhÃ¢n cáº¥p Ward táº¡o dendrogram rÃµ rÃ ng.)*

---

# ğŸ›  Installation  
*(CÃ i Ä‘áº·t)*  

```bash
pip install -r requirements.txt
```
python src/preprocess.py
python src/embedding.py
python src/clustering.py
python src/evaluate.py

## ğŸ‘¨â€ğŸ’» Authors (TÃ¡c giáº£)

Mai Thanh PhÃºc
HoÃ ng Thá»‹ Yáº¿n Nhi
Tráº§n Trá»ng ThÃ nh
Supervisor: LÃª Nháº­t TÃ¹ng (GVHD)

##ğŸ“š Citation (TrÃ­ch dáº«n)

Mai Thanh PhÃºc, HoÃ ng Thá»‹ Yáº¿n Nhi, Tráº§n Trá»ng ThÃ nh, LÃª Nháº­t TÃ¹ng. 
Clustering Electronic News Articles using NLP and Machine Learning.
HUTECH University.
